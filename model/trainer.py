"""
Module d'entraÃ®nement et de rÃ©-entraÃ®nement du modÃ¨le CNN
GÃ¨re la fusion des donnÃ©es (Sign Language + Feedback) et le fine-tuning
"""
import os
import shutil
import numpy as np
from PIL import Image
from datetime import datetime
from typing import List, Dict, Any, Tuple
from pathlib import Path

# Try to import TensorFlow
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    print("âš ï¸  TensorFlow n'est pas installÃ©. L'entraÃ®nement sera simulÃ©.")

# Try to import kagglehub
try:
    import kagglehub
    KAGGLEHUB_AVAILABLE = True
except ImportError:
    KAGGLEHUB_AVAILABLE = False
    print("âš ï¸  kagglehub n'est pas installÃ©. Impossible de tÃ©lÃ©charger le dataset.")

class ModelTrainer:
    """GÃ¨re le rÃ©-entraÃ®nement du modÃ¨le"""
    
    def __init__(self, db_manager, model_dir='model', input_size=(64, 64), classes=None):
        self.db_manager = db_manager
        self.model_dir = model_dir
        self.input_size = input_size
        # Classes par dÃ©faut (35 classes: 1-9, A-Z)
        default_classes = (
            '1,2,3,4,5,6,7,8,9,'
            'A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,'
            'P,Q,R,S,T,U,V,W,X,Y,Z'
        ).split(',')
        self.classes = classes or default_classes
        
        # Mapping des classes (label -> index)
        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}
        
    def retrain(self) -> Dict[str, Any]:
        """
        Lance le processus de rÃ©-entraÃ®nement complet
        
        Returns:
            Dict avec le statut et les infos
        """
        # 1. CrÃ©er le log d'entraÃ®nement
        run_id = self.db_manager.create_training_run()
        print(f"ðŸš€ DÃ©marrage de l'entraÃ®nement (Run ID: {run_id})")
        
        try:
            if not TF_AVAILABLE:
                return self._simulate_training(run_id, "TensorFlow manquant")
            
            if not KAGGLEHUB_AVAILABLE:
                return self._simulate_training(run_id, "kagglehub manquant")

            # 2. TÃ©lÃ©charger/Charger le dataset Kaggle
            print("ðŸ“¦ TÃ©lÃ©chargement/VÃ©rification du dataset Sign Language...")
            dataset_path = kagglehub.dataset_download("harshvardhan21/sign-language-detection-using-images")
            dataset_path = Path(dataset_path)
            print(f"   Dataset localisÃ©: {dataset_path}")
            
            # Trouver le dossier contenant les images
            data_dir = self._find_data_dir(dataset_path)
            if not data_dir:
                raise FileNotFoundError("Impossible de trouver le dossier d'images dans le dataset tÃ©lÃ©chargÃ©")
            
            print(f"   Dossier images: {data_dir}")

            # 3. PrÃ©parer les datasets (Train/Val)
            print("ðŸ”„ PrÃ©paration des datasets...")
            batch_size = 32
            img_size = self.input_size
            
            # Utiliser image_dataset_from_directory
            train_ds = tf.keras.utils.image_dataset_from_directory(
                str(data_dir),
                validation_split=0.2,
                subset="training",
                seed=123,
                image_size=img_size,
                batch_size=batch_size,
                label_mode='int' # Les labels seront des entiers correspondant Ã  l'ordre alphabÃ©tique des dossiers
            )
            
            val_ds = tf.keras.utils.image_dataset_from_directory(
                str(data_dir),
                validation_split=0.2,
                subset="validation",
                seed=123,
                image_size=img_size,
                batch_size=batch_size,
                label_mode='int'
            )
            
            # VÃ©rifier que les classes correspondent
            dataset_classes = train_ds.class_names
            print(f"   Classes trouvÃ©es dans le dataset: {len(dataset_classes)}")
            # Note: On suppose ici que les classes du dataset correspondent Ã  self.classes
            # IdÃ©alement, il faudrait faire un mapping si elles diffÃ¨rent.
            
            # Optimisation
            AUTOTUNE = tf.data.AUTOTUNE
            train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
            val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

            # 4. IntÃ©grer les feedbacks
            print("ðŸ” RÃ©cupÃ©ration des feedbacks utilisateurs...")
            feedback_data = self.db_manager.get_feedback_data_for_training()
            print(f"   {len(feedback_data)} images de feedback trouvÃ©es")
            
            if feedback_data:
                try:
                    feedback_images = []
                    feedback_labels = []
                    
                    for item in feedback_data:
                        try:
                            img_path = item['image_path']
                            true_label = item['user_feedback']['true_label']
                            
                            if true_label not in self.class_to_idx:
                                print(f"   âš ï¸ Label inconnu ignorÃ©: {true_label}")
                                continue
                                
                            if os.path.exists(img_path):
                                # Charger et prÃ©traiter l'image
                                img = Image.open(img_path)
                                # Convertir en RGB si nÃ©cessaire (le modÃ¨le attend 3 canaux)
                                img = img.convert('RGB')
                                img = img.resize(self.input_size)
                                img_arr = np.array(img).astype('float32') 
                                # Note: Rescaling layer dans le modÃ¨le fera la division / 255.
                                
                                feedback_images.append(img_arr)
                                feedback_labels.append(self.class_to_idx[true_label])
                        except Exception as e:
                            print(f"   Erreur image feedback: {e}")
                            
                    if feedback_images:
                        print(f"   âœ… {len(feedback_images)} images de feedback valides ajoutÃ©es")
                        
                        # CrÃ©er un dataset TensorFlow pour les feedbacks
                        feedback_ds = tf.data.Dataset.from_tensor_slices((
                            np.array(feedback_images),
                            np.array(feedback_labels)
                        ))
                        
                        # Batcher comme le dataset principal
                        feedback_ds = feedback_ds.shuffle(len(feedback_images)).batch(batch_size)
                        
                        # Fusionner avec le dataset d'entraÃ®nement
                        train_ds = train_ds.concatenate(feedback_ds)
                        
                        # Re-mÃ©langer le tout
                        train_ds = train_ds.shuffle(1000).prefetch(buffer_size=AUTOTUNE)
                        
                except Exception as e:
                    print(f"âš ï¸ Erreur lors de l'intÃ©gration des feedbacks: {e}")
            else:
                print("â„¹ï¸  Aucun feedback Ã  intÃ©grer")
            
            # 5. Construire le modÃ¨le
            print("ðŸ§  Construction du modÃ¨le CNN...")
            num_classes = len(dataset_classes)
            
            model = keras.Sequential([
                keras.layers.Input(shape=(*img_size, 3)),
                keras.layers.Rescaling(1./255),
                
                # Augmentation de donnÃ©es intÃ©grÃ©e
                keras.layers.RandomFlip("horizontal"),
                keras.layers.RandomRotation(0.1),
                keras.layers.RandomZoom(0.1),
                
                # Bloc 1
                keras.layers.Conv2D(32, (3, 3), activation="relu", padding="same"),
                keras.layers.MaxPooling2D((2, 2)),
                
                # Bloc 2
                keras.layers.Conv2D(64, (3, 3), activation="relu", padding="same"),
                keras.layers.MaxPooling2D((2, 2)),
                
                # Bloc 3
                keras.layers.Conv2D(128, (3, 3), activation="relu", padding="same"),
                keras.layers.MaxPooling2D((2, 2)),
                
                # Dense
                keras.layers.Flatten(),
                keras.layers.Dropout(0.5),
                keras.layers.Dense(256, activation="relu"),
                keras.layers.Dense(num_classes, activation="softmax")
            ])
            
            model.compile(
                optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy']
            )
            
            
            # 6. EntraÃ®ner avec callback de progression
            print("ðŸ”¥ Lancement de l'entraÃ®nement (5 Ã©poques)...")
            
            # CrÃ©er un callback pour mettre Ã  jour la progression
            class ProgressCallback(keras.callbacks.Callback):
                def __init__(self, db_manager, run_id, total_epochs):
                    super().__init__()
                    self.db_manager = db_manager
                    self.run_id = run_id
                    self.total_epochs = total_epochs
                    
                def on_epoch_end(self, epoch, logs=None):
                    # Calculer le pourcentage de progression (Ã©poque terminÃ©e + 1)
                    progress = ((epoch + 1) / self.total_epochs) * 100
                    message = f"Ã‰poque {epoch + 1}/{self.total_epochs} - Accuracy: {logs.get('accuracy', 0):.2%}"
                    
                    self.db_manager.update_training_progress(
                        run_id=self.run_id,
                        progress=progress,
                        current_epoch=epoch + 1,
                        total_epochs=self.total_epochs,
                        message=message
                    )
                    print(f"   Progression mise Ã  jour: {progress:.1f}%")
            
            total_epochs = 5
            progress_callback = ProgressCallback(self.db_manager, run_id, total_epochs)
            
            history = model.fit(
                train_ds,
                validation_data=val_ds,
                epochs=total_epochs,
                verbose=1,
                callbacks=[progress_callback]
            )
            
            # 7. Sauvegarder
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            new_model_name = f"cnn_model_{timestamp}.h5"
            new_model_path = os.path.join(self.model_dir, new_model_name)
            
            os.makedirs(self.model_dir, exist_ok=True)
            model.save(new_model_path)
            print(f"âœ… Nouveau modÃ¨le sauvegardÃ©: {new_model_path}")
            
            # Copier vers le modÃ¨le par dÃ©faut
            main_model_path = os.path.join(self.model_dir, 'sign_language_cnn.h5')
            try:
                shutil.copy2(new_model_path, main_model_path)
                print(f"âœ… ModÃ¨le principal mis Ã  jour: {main_model_path}")
            except Exception as e:
                print(f"âš ï¸ Erreur copie modÃ¨le principal: {e}")
            
            # 8. Update log
            self.db_manager.update_training_run(
                run_id=run_id,
                status="success",
                model_path=new_model_path,
                used_feedback_count=0
            )
            
            return {
                "status": "success", 
                "message": "ModÃ¨le rÃ©-entraÃ®nÃ© avec succÃ¨s sur le dataset Sign Language!",
                "model_path": new_model_path
            }
            
        except Exception as e:
            print(f"âŒ Erreur critique entraÃ®nement: {e}")
            import traceback
            traceback.print_exc()
            self.db_manager.update_training_run(
                run_id=run_id,
                status="failed",
                error_message=str(e)
            )
            return {"status": "error", "message": str(e)}

    def _simulate_training(self, run_id, reason):
        """Simule un entraÃ®nement si les dÃ©pendances manquent"""
        import time
        print(f"âš ï¸  Simulation d'entraÃ®nement ({reason})...")
        time.sleep(2)
        new_model_name = f"cnn_model_simulated_{datetime.now().strftime('%Y%m%d%H%M%S')}.h5"
        self.db_manager.update_training_run(
            run_id=run_id,
            status="success",
            model_path=os.path.join(self.model_dir, new_model_name),
            used_feedback_count=0
        )
        return {"status": "success", "message": f"EntraÃ®nement simulÃ© ({reason})"}

    def _find_data_dir(self, base_path: Path) -> Path:
        """Cherche rÃ©cursivement le dossier contenant les images"""
        # StratÃ©gie: chercher un dossier qui contient des sous-dossiers (classes)
        # qui eux-mÃªmes contiennent des images.
        for p in base_path.rglob('*'):
            if p.is_dir():
                subdirs = [d for d in p.iterdir() if d.is_dir()]
                if len(subdirs) > 1: # Au moins 2 classes
                    # VÃ©rifier si le premier sous-dossier contient des images
                    first_class = subdirs[0]
                    has_images = any(first_class.glob('*.jpg')) or any(first_class.glob('*.png'))
                    if has_images:
                        return p
        return None
